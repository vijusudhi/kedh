{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "54KVmbWPCZGn"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWKNdGbu-BjI",
    "outputId": "cf3c6428-fee4-4ecc-dd54-fb92c10bd3e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet as wn  # to get the synsets\n",
    "from nltk.corpus import stopwords  # common stop words in English\n",
    "from nltk.tokenize import word_tokenize  # to tokenize the sentences\n",
    "from nltk.wsd import lesk # fow word sense disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ci5jHeI_BoX3"
   },
   "source": [
    "**Word sense disambiguation**\n",
    "\n",
    "a word with multiple word senses --> arouses ambiguity\n",
    "\n",
    "WSD --> identifies the right word sense\n",
    "\n",
    "improving relevance of search engines, anaphora resolution, coherence, and inference. \n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Word-sense_disambiguation\n",
    "\n",
    "**LESK algorithm**\n",
    "\n",
    "Given an ambiguous word and the context in which the word occurs, Lesk returns a Synset with the highest number of overlapping words between the context sentence and different definitions from each Synset.\n",
    "\n",
    "Original paper: https://dl.acm.org/doi/pdf/10.1145/318723.318728\n",
    "\n",
    "Ref: https://web.stanford.edu/~jurafsky/slp3/slides/Chapter18.wsd.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NsNxBNMN7rFa"
   },
   "outputs": [],
   "source": [
    "sent_1 = \"A rock is classified according to characteristics such as mineral and chemical composition.\"\n",
    "sent_2 = \"Queen are a British rock band formed in London in 1970.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3mquikU-Hjo",
    "outputId": "f5fa5421-ed40-496a-edd5-1fa363ac044e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Definition of each synset of the word 'rock'\n",
      "Synset('rock.n.01') \t\t a lump or mass of hard consolidated mineral matter\n",
      "Synset('rock.n.02') \t\t material consisting of the aggregate of minerals like those making up the Earth's crust\n",
      "Synset('rock.n.03') \t\t United States gynecologist and devout Catholic who conducted the first clinical trials of the oral contraceptive pill (1890-1984)\n",
      "Synset('rock.n.04') \t\t (figurative) someone who is strong and stable and dependable; ; --Gospel According to Matthew\n",
      "Synset('rock_candy.n.01') \t\t hard bright-colored stick candy (typically flavored with peppermint)\n",
      "Synset('rock_'n'_roll.n.01') \t\t a genre of popular music originating in the 1950s; a blend of black rhythm-and-blues with white country-and-western\n",
      "Synset('rock.n.07') \t\t pitching dangerously to one side\n",
      "Synset('rock.v.01') \t\t move back and forth or sideways\n",
      "Synset('rock.v.02') \t\t cause to move back and forth\n"
     ]
    }
   ],
   "source": [
    "# For example, given a word 'rock', WordNet gives different sysnets for this word.\n",
    "# For each of the sysnet, we can find the definition from WordNet.\n",
    "print(\"\\nDefinition of each synset of the word 'rock'\")\n",
    "for syn in wn.synsets('rock'):\n",
    "  print(syn, '\\t\\t', syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzKvCp-lEBv7",
    "outputId": "d5dc1574-9ef3-475f-c49e-f8faae2ab6ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i',\n",
      " 'me',\n",
      " 'my',\n",
      " 'myself',\n",
      " 'we',\n",
      " 'our',\n",
      " 'ours',\n",
      " 'ourselves',\n",
      " 'you',\n",
      " \"you're\",\n",
      " \"you've\",\n",
      " \"you'll\",\n",
      " \"you'd\",\n",
      " 'your',\n",
      " 'yours',\n",
      " 'yourself',\n",
      " 'yourselves',\n",
      " 'he',\n",
      " 'him',\n",
      " 'his',\n",
      " 'himself',\n",
      " 'she',\n",
      " \"she's\",\n",
      " 'her',\n",
      " 'hers',\n",
      " 'herself',\n",
      " 'it',\n",
      " \"it's\",\n",
      " 'its',\n",
      " 'itself',\n",
      " 'they',\n",
      " 'them',\n",
      " 'their',\n",
      " 'theirs',\n",
      " 'themselves',\n",
      " 'what',\n",
      " 'which',\n",
      " 'who',\n",
      " 'whom',\n",
      " 'this',\n",
      " 'that',\n",
      " \"that'll\",\n",
      " 'these',\n",
      " 'those',\n",
      " 'am',\n",
      " 'is',\n",
      " 'are',\n",
      " 'was',\n",
      " 'were',\n",
      " 'be',\n",
      " 'been',\n",
      " 'being',\n",
      " 'have',\n",
      " 'has',\n",
      " 'had',\n",
      " 'having',\n",
      " 'do',\n",
      " 'does',\n",
      " 'did',\n",
      " 'doing',\n",
      " 'a',\n",
      " 'an',\n",
      " 'the',\n",
      " 'and',\n",
      " 'but',\n",
      " 'if',\n",
      " 'or',\n",
      " 'because',\n",
      " 'as',\n",
      " 'until',\n",
      " 'while',\n",
      " 'of',\n",
      " 'at',\n",
      " 'by',\n",
      " 'for',\n",
      " 'with',\n",
      " 'about',\n",
      " 'against',\n",
      " 'between',\n",
      " 'into',\n",
      " 'through',\n",
      " 'during',\n",
      " 'before',\n",
      " 'after',\n",
      " 'above',\n",
      " 'below',\n",
      " 'to',\n",
      " 'from',\n",
      " 'up',\n",
      " 'down',\n",
      " 'in',\n",
      " 'out',\n",
      " 'on',\n",
      " 'off',\n",
      " 'over',\n",
      " 'under',\n",
      " 'again',\n",
      " 'further',\n",
      " 'then',\n",
      " 'once',\n",
      " 'here',\n",
      " 'there',\n",
      " 'when',\n",
      " 'where',\n",
      " 'why',\n",
      " 'how',\n",
      " 'all',\n",
      " 'any',\n",
      " 'both',\n",
      " 'each',\n",
      " 'few',\n",
      " 'more',\n",
      " 'most',\n",
      " 'other',\n",
      " 'some',\n",
      " 'such',\n",
      " 'no',\n",
      " 'nor',\n",
      " 'not',\n",
      " 'only',\n",
      " 'own',\n",
      " 'same',\n",
      " 'so',\n",
      " 'than',\n",
      " 'too',\n",
      " 'very',\n",
      " 's',\n",
      " 't',\n",
      " 'can',\n",
      " 'will',\n",
      " 'just',\n",
      " 'don',\n",
      " \"don't\",\n",
      " 'should',\n",
      " \"should've\",\n",
      " 'now',\n",
      " 'd',\n",
      " 'll',\n",
      " 'm',\n",
      " 'o',\n",
      " 're',\n",
      " 've',\n",
      " 'y',\n",
      " 'ain',\n",
      " 'aren',\n",
      " \"aren't\",\n",
      " 'couldn',\n",
      " \"couldn't\",\n",
      " 'didn',\n",
      " \"didn't\",\n",
      " 'doesn',\n",
      " \"doesn't\",\n",
      " 'hadn',\n",
      " \"hadn't\",\n",
      " 'hasn',\n",
      " \"hasn't\",\n",
      " 'haven',\n",
      " \"haven't\",\n",
      " 'isn',\n",
      " \"isn't\",\n",
      " 'ma',\n",
      " 'mightn',\n",
      " \"mightn't\",\n",
      " 'mustn',\n",
      " \"mustn't\",\n",
      " 'needn',\n",
      " \"needn't\",\n",
      " 'shan',\n",
      " \"shan't\",\n",
      " 'shouldn',\n",
      " \"shouldn't\",\n",
      " 'wasn',\n",
      " \"wasn't\",\n",
      " 'weren',\n",
      " \"weren't\",\n",
      " 'won',\n",
      " \"won't\",\n",
      " 'wouldn',\n",
      " \"wouldn't\"]\n",
      "\n",
      "There are 179 stop words in the list\n"
     ]
    }
   ],
   "source": [
    "# Common stop words in English\n",
    "pprint(stopwords.words('english'))\n",
    "\n",
    "print(\"\\nThere are %d stop words in the list\" \n",
    "      % (len(stopwords.words('english'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Qy_yxTPPA3PN"
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):\n",
    "  \"\"\"\n",
    "  this function removes the stop words from the list of tokens\n",
    "  \"\"\"\n",
    "  # Get the list of common stop words in English from WordNet\n",
    "  stop_words = stopwords.words('english')\n",
    "  tokens_filtered = []\n",
    "  # Iterate through the list of tokens\n",
    "  for token in tokens:\n",
    "    # If the token is not a stop word, add it to the new list\n",
    "    if token not in stop_words:\n",
    "      tokens_filtered.append(token)\n",
    "  return tokens_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdQWXpgkCHZl"
   },
   "source": [
    "## Without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cw91lYN-CROI",
    "outputId": "506d2e22-b8da-4545-b451-2f5fa1c92f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rock.n.04') \n",
      " (figurative) someone who is strong and stable and dependable; ; --Gospel According to Matthew\n"
     ]
    }
   ],
   "source": [
    "# Giving the POS\n",
    "syn = lesk(word_tokenize(sent_1), 'rock', 'n')\n",
    "print(syn, '\\n', syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3zUdOEcCYkD",
    "outputId": "c3721116-de2b-4ad3-b27a-6d76e95765dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rock_'n'_roll.n.01') \n",
      " a genre of popular music originating in the 1950s; a blend of black rhythm-and-blues with white country-and-western\n"
     ]
    }
   ],
   "source": [
    "# Giving the POS\n",
    "syn = lesk(word_tokenize(sent_2), 'rock', 'n')\n",
    "print(syn, '\\n', syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4c3e8wBCaKd",
    "outputId": "95fe79ff-3b5f-4ba9-8585-36c66b10a912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rock.v.02') \n",
      " cause to move back and forth\n"
     ]
    }
   ],
   "source": [
    "# w/o giving the POS\n",
    "syn = lesk(word_tokenize(sent_1), 'rock')\n",
    "print(syn, '\\n', syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STdlNLo3CeC3",
    "outputId": "ee7fa72e-728b-4d2e-d779-a635671554fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rock_'n'_roll.n.01') \n",
      " a genre of popular music originating in the 1950s; a blend of black rhythm-and-blues with white country-and-western\n"
     ]
    }
   ],
   "source": [
    "# w/o giving the POS\n",
    "syn = lesk(word_tokenize(sent_2), 'rock')\n",
    "print(syn, '\\n', syn.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIgA21v-CLM_"
   },
   "source": [
    "## With stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qt_KotA172dm",
    "outputId": "0157ae70-1c26-49fa-998e-b465f3ab6d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rock.n.01') \n",
      " a lump or mass of hard consolidated mineral matter\n"
     ]
    }
   ],
   "source": [
    "# Giving POS\n",
    "syn = lesk(remove_stop_words(word_tokenize(sent_1)), 'rock', 'n')\n",
    "print(syn, '\\n', syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sij7EMV38MCs",
    "outputId": "085d7ec7-37d6-41dd-931b-d781a3e2e16d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rock_candy.n.01') \n",
      " hard bright-colored stick candy (typically flavored with peppermint)\n"
     ]
    }
   ],
   "source": [
    "# Giving POS\n",
    "syn = lesk(remove_stop_words(word_tokenize(sent_2)), 'rock', 'n')\n",
    "print(syn, '\\n', syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZbVSH21gCkqE",
    "outputId": "a09b7e37-27b7-4af1-8a0b-abb9d4c13295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rock.n.01') \n",
      " a lump or mass of hard consolidated mineral matter\n"
     ]
    }
   ],
   "source": [
    "# w/o giving POS\n",
    "syn = lesk(remove_stop_words(word_tokenize(sent_1)), 'rock')\n",
    "print(syn, '\\n', syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wk4F3PGWEdsz",
    "outputId": "1fdbef1f-d0bb-4183-9d1c-67444d4fecef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rock_candy.n.01') \n",
      " hard bright-colored stick candy (typically flavored with peppermint)\n"
     ]
    }
   ],
   "source": [
    "# w/o giving POS\n",
    "syn = lesk(remove_stop_words(word_tokenize(sent_2)), 'rock')\n",
    "print(syn, '\\n', syn.definition())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sudhi-lecture4-nltk-wsd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
